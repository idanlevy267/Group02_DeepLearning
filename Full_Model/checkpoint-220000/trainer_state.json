{
  "best_metric": 0.7602975236059148,
  "best_model_checkpoint": "/content/drive/MyDrive/DeepLearning - Headlines Proj/Balanced Data Training/distilbert_full/20230526-082425/checkpoint-220000",
  "epoch": 3.9194726527703545,
  "global_step": 220000,
  "is_hyper_param_search": false,
  "is_local_process_zero": true,
  "is_world_process_zero": true,
  "log_history": [
    {
      "epoch": 0.01,
      "learning_rate": 1.4253135689851768e-06,
      "loss": 1.7841,
      "step": 500
    },
    {
      "epoch": 0.02,
      "learning_rate": 2.8506271379703537e-06,
      "loss": 1.6845,
      "step": 1000
    },
    {
      "epoch": 0.03,
      "learning_rate": 4.27594070695553e-06,
      "loss": 1.5041,
      "step": 1500
    },
    {
      "epoch": 0.04,
      "learning_rate": 5.701254275940707e-06,
      "loss": 1.4508,
      "step": 2000
    },
    {
      "epoch": 0.04,
      "learning_rate": 7.1265678449258844e-06,
      "loss": 1.3648,
      "step": 2500
    },
    {
      "epoch": 0.05,
      "learning_rate": 8.55188141391106e-06,
      "loss": 1.3449,
      "step": 3000
    },
    {
      "epoch": 0.06,
      "learning_rate": 9.977194982896238e-06,
      "loss": 1.3206,
      "step": 3500
    },
    {
      "epoch": 0.07,
      "learning_rate": 1.1402508551881415e-05,
      "loss": 1.3018,
      "step": 4000
    },
    {
      "epoch": 0.08,
      "learning_rate": 1.2827822120866592e-05,
      "loss": 1.2905,
      "step": 4500
    },
    {
      "epoch": 0.09,
      "learning_rate": 1.4253135689851769e-05,
      "loss": 1.2691,
      "step": 5000
    },
    {
      "epoch": 0.1,
      "learning_rate": 1.5678449258836944e-05,
      "loss": 1.2522,
      "step": 5500
    },
    {
      "epoch": 0.11,
      "learning_rate": 1.710376282782212e-05,
      "loss": 1.2637,
      "step": 6000
    },
    {
      "epoch": 0.12,
      "learning_rate": 1.85290763968073e-05,
      "loss": 1.2402,
      "step": 6500
    },
    {
      "epoch": 0.12,
      "learning_rate": 1.9954389965792475e-05,
      "loss": 1.2341,
      "step": 7000
    },
    {
      "epoch": 0.13,
      "learning_rate": 2.1379703534777652e-05,
      "loss": 1.2146,
      "step": 7500
    },
    {
      "epoch": 0.14,
      "learning_rate": 2.280501710376283e-05,
      "loss": 1.2321,
      "step": 8000
    },
    {
      "epoch": 0.15,
      "learning_rate": 2.4230330672748007e-05,
      "loss": 1.2227,
      "step": 8500
    },
    {
      "epoch": 0.16,
      "learning_rate": 2.5655644241733184e-05,
      "loss": 1.2013,
      "step": 9000
    },
    {
      "epoch": 0.17,
      "learning_rate": 2.708095781071836e-05,
      "loss": 1.2202,
      "step": 9500
    },
    {
      "epoch": 0.18,
      "learning_rate": 2.8506271379703538e-05,
      "loss": 1.2086,
      "step": 10000
    },
    {
      "epoch": 0.19,
      "learning_rate": 2.993158494868871e-05,
      "loss": 1.2124,
      "step": 10500
    },
    {
      "epoch": 0.2,
      "learning_rate": 3.135689851767389e-05,
      "loss": 1.1882,
      "step": 11000
    },
    {
      "epoch": 0.2,
      "learning_rate": 3.2782212086659065e-05,
      "loss": 1.2034,
      "step": 11500
    },
    {
      "epoch": 0.21,
      "learning_rate": 3.420752565564424e-05,
      "loss": 1.1834,
      "step": 12000
    },
    {
      "epoch": 0.22,
      "learning_rate": 3.563283922462942e-05,
      "loss": 1.1942,
      "step": 12500
    },
    {
      "epoch": 0.23,
      "learning_rate": 3.70581527936146e-05,
      "loss": 1.1859,
      "step": 13000
    },
    {
      "epoch": 0.24,
      "learning_rate": 3.848346636259978e-05,
      "loss": 1.1918,
      "step": 13500
    },
    {
      "epoch": 0.25,
      "learning_rate": 3.990877993158495e-05,
      "loss": 1.1947,
      "step": 14000
    },
    {
      "epoch": 0.26,
      "learning_rate": 3.992978718616148e-05,
      "loss": 1.1956,
      "step": 14500
    },
    {
      "epoch": 0.27,
      "learning_rate": 3.985477349616306e-05,
      "loss": 1.1787,
      "step": 15000
    },
    {
      "epoch": 0.28,
      "learning_rate": 3.977975980616463e-05,
      "loss": 1.1829,
      "step": 15500
    },
    {
      "epoch": 0.29,
      "learning_rate": 3.9704746116166203e-05,
      "loss": 1.1766,
      "step": 16000
    },
    {
      "epoch": 0.29,
      "learning_rate": 3.962973242616778e-05,
      "loss": 1.189,
      "step": 16500
    },
    {
      "epoch": 0.3,
      "learning_rate": 3.955471873616935e-05,
      "loss": 1.1739,
      "step": 17000
    },
    {
      "epoch": 0.31,
      "learning_rate": 3.9479705046170934e-05,
      "loss": 1.1894,
      "step": 17500
    },
    {
      "epoch": 0.32,
      "learning_rate": 3.9404691356172504e-05,
      "loss": 1.1634,
      "step": 18000
    },
    {
      "epoch": 0.33,
      "learning_rate": 3.932967766617408e-05,
      "loss": 1.1772,
      "step": 18500
    },
    {
      "epoch": 0.34,
      "learning_rate": 3.925466397617566e-05,
      "loss": 1.1666,
      "step": 19000
    },
    {
      "epoch": 0.35,
      "learning_rate": 3.917965028617723e-05,
      "loss": 1.1491,
      "step": 19500
    },
    {
      "epoch": 0.36,
      "learning_rate": 3.9104636596178804e-05,
      "loss": 1.1573,
      "step": 20000
    },
    {
      "epoch": 0.36,
      "eval_accuracy": 0.7034607161945484,
      "eval_f1": 0.699400332148781,
      "eval_loss": 0.8399711847305298,
      "eval_precision": 0.7017994258799023,
      "eval_recall": 0.7034607161945484,
      "eval_runtime": 264.2899,
      "eval_samples_per_second": 849.522,
      "eval_steps_per_second": 106.19,
      "step": 20000
    },
    {
      "epoch": 0.37,
      "learning_rate": 3.902962290618038e-05,
      "loss": 1.1592,
      "step": 20500
    },
    {
      "epoch": 0.37,
      "learning_rate": 3.895460921618196e-05,
      "loss": 1.1556,
      "step": 21000
    },
    {
      "epoch": 0.38,
      "learning_rate": 3.8879595526183534e-05,
      "loss": 1.1595,
      "step": 21500
    },
    {
      "epoch": 0.39,
      "learning_rate": 3.880458183618511e-05,
      "loss": 1.15,
      "step": 22000
    },
    {
      "epoch": 0.4,
      "learning_rate": 3.872956814618668e-05,
      "loss": 1.1614,
      "step": 22500
    },
    {
      "epoch": 0.41,
      "learning_rate": 3.865455445618826e-05,
      "loss": 1.1447,
      "step": 23000
    },
    {
      "epoch": 0.42,
      "learning_rate": 3.8579540766189834e-05,
      "loss": 1.1296,
      "step": 23500
    },
    {
      "epoch": 0.43,
      "learning_rate": 3.8504527076191404e-05,
      "loss": 1.1549,
      "step": 24000
    },
    {
      "epoch": 0.44,
      "learning_rate": 3.842951338619299e-05,
      "loss": 1.1319,
      "step": 24500
    },
    {
      "epoch": 0.45,
      "learning_rate": 3.835449969619456e-05,
      "loss": 1.1603,
      "step": 25000
    },
    {
      "epoch": 0.45,
      "learning_rate": 3.8279486006196134e-05,
      "loss": 1.1339,
      "step": 25500
    },
    {
      "epoch": 0.46,
      "learning_rate": 3.820447231619771e-05,
      "loss": 1.1379,
      "step": 26000
    },
    {
      "epoch": 0.47,
      "learning_rate": 3.812945862619928e-05,
      "loss": 1.1331,
      "step": 26500
    },
    {
      "epoch": 0.48,
      "learning_rate": 3.805444493620086e-05,
      "loss": 1.1275,
      "step": 27000
    },
    {
      "epoch": 0.49,
      "learning_rate": 3.7979431246202434e-05,
      "loss": 1.1184,
      "step": 27500
    },
    {
      "epoch": 0.5,
      "learning_rate": 3.790441755620401e-05,
      "loss": 1.1392,
      "step": 28000
    },
    {
      "epoch": 0.51,
      "learning_rate": 3.782940386620559e-05,
      "loss": 1.1111,
      "step": 28500
    },
    {
      "epoch": 0.52,
      "learning_rate": 3.7754390176207164e-05,
      "loss": 1.1215,
      "step": 29000
    },
    {
      "epoch": 0.53,
      "learning_rate": 3.7679376486208734e-05,
      "loss": 1.1109,
      "step": 29500
    },
    {
      "epoch": 0.53,
      "learning_rate": 3.760436279621031e-05,
      "loss": 1.1159,
      "step": 30000
    },
    {
      "epoch": 0.54,
      "learning_rate": 3.752934910621189e-05,
      "loss": 1.1256,
      "step": 30500
    },
    {
      "epoch": 0.55,
      "learning_rate": 3.745433541621346e-05,
      "loss": 1.1232,
      "step": 31000
    },
    {
      "epoch": 0.56,
      "learning_rate": 3.737932172621504e-05,
      "loss": 1.1212,
      "step": 31500
    },
    {
      "epoch": 0.57,
      "learning_rate": 3.730430803621661e-05,
      "loss": 1.1107,
      "step": 32000
    },
    {
      "epoch": 0.58,
      "learning_rate": 3.722929434621819e-05,
      "loss": 1.1269,
      "step": 32500
    },
    {
      "epoch": 0.59,
      "learning_rate": 3.7154280656219765e-05,
      "loss": 1.1102,
      "step": 33000
    },
    {
      "epoch": 0.6,
      "learning_rate": 3.7079266966221335e-05,
      "loss": 1.0962,
      "step": 33500
    },
    {
      "epoch": 0.61,
      "learning_rate": 3.700425327622291e-05,
      "loss": 1.126,
      "step": 34000
    },
    {
      "epoch": 0.61,
      "learning_rate": 3.692923958622449e-05,
      "loss": 1.1196,
      "step": 34500
    },
    {
      "epoch": 0.62,
      "learning_rate": 3.6854225896226065e-05,
      "loss": 1.1253,
      "step": 35000
    },
    {
      "epoch": 0.63,
      "learning_rate": 3.677921220622764e-05,
      "loss": 1.1061,
      "step": 35500
    },
    {
      "epoch": 0.64,
      "learning_rate": 3.670419851622922e-05,
      "loss": 1.0925,
      "step": 36000
    },
    {
      "epoch": 0.65,
      "learning_rate": 3.662918482623079e-05,
      "loss": 1.1041,
      "step": 36500
    },
    {
      "epoch": 0.66,
      "learning_rate": 3.6554171136232365e-05,
      "loss": 1.1185,
      "step": 37000
    },
    {
      "epoch": 0.67,
      "learning_rate": 3.647915744623394e-05,
      "loss": 1.1004,
      "step": 37500
    },
    {
      "epoch": 0.68,
      "learning_rate": 3.640414375623551e-05,
      "loss": 1.1112,
      "step": 38000
    },
    {
      "epoch": 0.69,
      "learning_rate": 3.6329130066237095e-05,
      "loss": 1.1166,
      "step": 38500
    },
    {
      "epoch": 0.69,
      "learning_rate": 3.6254116376238665e-05,
      "loss": 1.1068,
      "step": 39000
    },
    {
      "epoch": 0.7,
      "learning_rate": 3.617910268624024e-05,
      "loss": 1.0957,
      "step": 39500
    },
    {
      "epoch": 0.71,
      "learning_rate": 3.610408899624182e-05,
      "loss": 1.1064,
      "step": 40000
    },
    {
      "epoch": 0.71,
      "eval_accuracy": 0.7181631925886335,
      "eval_f1": 0.7146758873490123,
      "eval_loss": 0.8013856410980225,
      "eval_precision": 0.7152327682478907,
      "eval_recall": 0.7181631925886335,
      "eval_runtime": 266.5469,
      "eval_samples_per_second": 842.328,
      "eval_steps_per_second": 105.291,
      "step": 40000
    },
    {
      "epoch": 0.72,
      "learning_rate": 3.602907530624339e-05,
      "loss": 1.1006,
      "step": 40500
    },
    {
      "epoch": 0.73,
      "learning_rate": 3.5954061616244965e-05,
      "loss": 1.1162,
      "step": 41000
    },
    {
      "epoch": 0.74,
      "learning_rate": 3.587904792624654e-05,
      "loss": 1.0906,
      "step": 41500
    },
    {
      "epoch": 0.75,
      "learning_rate": 3.580403423624812e-05,
      "loss": 1.1048,
      "step": 42000
    },
    {
      "epoch": 0.76,
      "learning_rate": 3.5729020546249695e-05,
      "loss": 1.0999,
      "step": 42500
    },
    {
      "epoch": 0.77,
      "learning_rate": 3.565400685625127e-05,
      "loss": 1.0975,
      "step": 43000
    },
    {
      "epoch": 0.77,
      "learning_rate": 3.557899316625284e-05,
      "loss": 1.0921,
      "step": 43500
    },
    {
      "epoch": 0.78,
      "learning_rate": 3.550397947625442e-05,
      "loss": 1.07,
      "step": 44000
    },
    {
      "epoch": 0.79,
      "learning_rate": 3.5428965786255996e-05,
      "loss": 1.0699,
      "step": 44500
    },
    {
      "epoch": 0.8,
      "learning_rate": 3.535395209625757e-05,
      "loss": 1.0878,
      "step": 45000
    },
    {
      "epoch": 0.81,
      "learning_rate": 3.527893840625915e-05,
      "loss": 1.0872,
      "step": 45500
    },
    {
      "epoch": 0.82,
      "learning_rate": 3.520392471626072e-05,
      "loss": 1.0916,
      "step": 46000
    },
    {
      "epoch": 0.83,
      "learning_rate": 3.5128911026262296e-05,
      "loss": 1.1077,
      "step": 46500
    },
    {
      "epoch": 0.84,
      "learning_rate": 3.505389733626387e-05,
      "loss": 1.1134,
      "step": 47000
    },
    {
      "epoch": 0.85,
      "learning_rate": 3.497888364626544e-05,
      "loss": 1.0974,
      "step": 47500
    },
    {
      "epoch": 0.86,
      "learning_rate": 3.4903869956267026e-05,
      "loss": 1.1092,
      "step": 48000
    },
    {
      "epoch": 0.86,
      "learning_rate": 3.4828856266268596e-05,
      "loss": 1.0908,
      "step": 48500
    },
    {
      "epoch": 0.87,
      "learning_rate": 3.475384257627017e-05,
      "loss": 1.0804,
      "step": 49000
    },
    {
      "epoch": 0.88,
      "learning_rate": 3.467882888627175e-05,
      "loss": 1.0982,
      "step": 49500
    },
    {
      "epoch": 0.89,
      "learning_rate": 3.4603815196273326e-05,
      "loss": 1.0969,
      "step": 50000
    },
    {
      "epoch": 0.9,
      "learning_rate": 3.4528801506274896e-05,
      "loss": 1.0976,
      "step": 50500
    },
    {
      "epoch": 0.91,
      "learning_rate": 3.445378781627647e-05,
      "loss": 1.0929,
      "step": 51000
    },
    {
      "epoch": 0.92,
      "learning_rate": 3.437877412627805e-05,
      "loss": 1.086,
      "step": 51500
    },
    {
      "epoch": 0.93,
      "learning_rate": 3.4303760436279626e-05,
      "loss": 1.0716,
      "step": 52000
    },
    {
      "epoch": 0.94,
      "learning_rate": 3.42287467462812e-05,
      "loss": 1.0843,
      "step": 52500
    },
    {
      "epoch": 0.94,
      "learning_rate": 3.415373305628277e-05,
      "loss": 1.0907,
      "step": 53000
    },
    {
      "epoch": 0.95,
      "learning_rate": 3.407871936628435e-05,
      "loss": 1.0995,
      "step": 53500
    },
    {
      "epoch": 0.96,
      "learning_rate": 3.4003705676285926e-05,
      "loss": 1.096,
      "step": 54000
    },
    {
      "epoch": 0.97,
      "learning_rate": 3.3928691986287496e-05,
      "loss": 1.0853,
      "step": 54500
    },
    {
      "epoch": 0.98,
      "learning_rate": 3.385367829628908e-05,
      "loss": 1.1053,
      "step": 55000
    },
    {
      "epoch": 0.99,
      "learning_rate": 3.377866460629065e-05,
      "loss": 1.0864,
      "step": 55500
    },
    {
      "epoch": 1.0,
      "learning_rate": 3.3703650916292226e-05,
      "loss": 1.0691,
      "step": 56000
    },
    {
      "epoch": 1.01,
      "learning_rate": 3.36286372262938e-05,
      "loss": 1.0239,
      "step": 56500
    },
    {
      "epoch": 1.02,
      "learning_rate": 3.355362353629538e-05,
      "loss": 0.9985,
      "step": 57000
    },
    {
      "epoch": 1.02,
      "learning_rate": 3.347860984629695e-05,
      "loss": 1.0085,
      "step": 57500
    },
    {
      "epoch": 1.03,
      "learning_rate": 3.3403596156298526e-05,
      "loss": 0.9968,
      "step": 58000
    },
    {
      "epoch": 1.04,
      "learning_rate": 3.33285824663001e-05,
      "loss": 1.0093,
      "step": 58500
    },
    {
      "epoch": 1.05,
      "learning_rate": 3.325356877630168e-05,
      "loss": 1.0133,
      "step": 59000
    },
    {
      "epoch": 1.06,
      "learning_rate": 3.317855508630326e-05,
      "loss": 0.9962,
      "step": 59500
    },
    {
      "epoch": 1.07,
      "learning_rate": 3.3103541396304827e-05,
      "loss": 0.9873,
      "step": 60000
    },
    {
      "epoch": 1.07,
      "eval_accuracy": 0.7255790130055229,
      "eval_f1": 0.72215504000092,
      "eval_loss": 0.7930973172187805,
      "eval_precision": 0.7231931753127269,
      "eval_recall": 0.7255790130055229,
      "eval_runtime": 271.3651,
      "eval_samples_per_second": 827.372,
      "eval_steps_per_second": 103.422,
      "step": 60000
    },
    {
      "epoch": 1.08,
      "learning_rate": 3.30285277063064e-05,
      "loss": 0.9997,
      "step": 60500
    },
    {
      "epoch": 1.09,
      "learning_rate": 3.295351401630798e-05,
      "loss": 1.0086,
      "step": 61000
    },
    {
      "epoch": 1.1,
      "learning_rate": 3.287850032630955e-05,
      "loss": 1.0267,
      "step": 61500
    },
    {
      "epoch": 1.1,
      "learning_rate": 3.2803486636311133e-05,
      "loss": 0.9889,
      "step": 62000
    },
    {
      "epoch": 1.11,
      "learning_rate": 3.2728472946312703e-05,
      "loss": 0.9995,
      "step": 62500
    },
    {
      "epoch": 1.12,
      "learning_rate": 3.265345925631428e-05,
      "loss": 0.9956,
      "step": 63000
    },
    {
      "epoch": 1.13,
      "learning_rate": 3.257844556631586e-05,
      "loss": 1.0121,
      "step": 63500
    },
    {
      "epoch": 1.14,
      "learning_rate": 3.2503431876317434e-05,
      "loss": 1.0083,
      "step": 64000
    },
    {
      "epoch": 1.15,
      "learning_rate": 3.2428418186319004e-05,
      "loss": 0.9848,
      "step": 64500
    },
    {
      "epoch": 1.16,
      "learning_rate": 3.235340449632058e-05,
      "loss": 0.9955,
      "step": 65000
    },
    {
      "epoch": 1.17,
      "learning_rate": 3.227839080632216e-05,
      "loss": 1.0138,
      "step": 65500
    },
    {
      "epoch": 1.18,
      "learning_rate": 3.2203377116323734e-05,
      "loss": 1.0027,
      "step": 66000
    },
    {
      "epoch": 1.18,
      "learning_rate": 3.212836342632531e-05,
      "loss": 1.004,
      "step": 66500
    },
    {
      "epoch": 1.19,
      "learning_rate": 3.205334973632688e-05,
      "loss": 0.9792,
      "step": 67000
    },
    {
      "epoch": 1.2,
      "learning_rate": 3.197833604632846e-05,
      "loss": 1.0009,
      "step": 67500
    },
    {
      "epoch": 1.21,
      "learning_rate": 3.1903322356330034e-05,
      "loss": 0.9883,
      "step": 68000
    },
    {
      "epoch": 1.22,
      "learning_rate": 3.1828308666331604e-05,
      "loss": 1.0041,
      "step": 68500
    },
    {
      "epoch": 1.23,
      "learning_rate": 3.175329497633319e-05,
      "loss": 1.009,
      "step": 69000
    },
    {
      "epoch": 1.24,
      "learning_rate": 3.167828128633476e-05,
      "loss": 0.9946,
      "step": 69500
    },
    {
      "epoch": 1.25,
      "learning_rate": 3.1603267596336334e-05,
      "loss": 1.0112,
      "step": 70000
    },
    {
      "epoch": 1.26,
      "learning_rate": 3.152825390633791e-05,
      "loss": 1.0036,
      "step": 70500
    },
    {
      "epoch": 1.26,
      "learning_rate": 3.145324021633948e-05,
      "loss": 1.0057,
      "step": 71000
    },
    {
      "epoch": 1.27,
      "learning_rate": 3.137822652634106e-05,
      "loss": 1.0081,
      "step": 71500
    },
    {
      "epoch": 1.28,
      "learning_rate": 3.1303212836342634e-05,
      "loss": 0.9786,
      "step": 72000
    },
    {
      "epoch": 1.29,
      "learning_rate": 3.122819914634421e-05,
      "loss": 1.0208,
      "step": 72500
    },
    {
      "epoch": 1.3,
      "learning_rate": 3.115318545634579e-05,
      "loss": 1.0217,
      "step": 73000
    },
    {
      "epoch": 1.31,
      "learning_rate": 3.1078171766347364e-05,
      "loss": 0.9977,
      "step": 73500
    },
    {
      "epoch": 1.32,
      "learning_rate": 3.1003158076348934e-05,
      "loss": 1.0001,
      "step": 74000
    },
    {
      "epoch": 1.33,
      "learning_rate": 3.092814438635051e-05,
      "loss": 0.9941,
      "step": 74500
    },
    {
      "epoch": 1.34,
      "learning_rate": 3.085313069635209e-05,
      "loss": 0.9956,
      "step": 75000
    },
    {
      "epoch": 1.35,
      "learning_rate": 3.077811700635366e-05,
      "loss": 1.0019,
      "step": 75500
    },
    {
      "epoch": 1.35,
      "learning_rate": 3.070310331635524e-05,
      "loss": 0.9959,
      "step": 76000
    },
    {
      "epoch": 1.36,
      "learning_rate": 3.062808962635681e-05,
      "loss": 0.9992,
      "step": 76500
    },
    {
      "epoch": 1.37,
      "learning_rate": 3.055307593635839e-05,
      "loss": 1.0157,
      "step": 77000
    },
    {
      "epoch": 1.38,
      "learning_rate": 3.0478062246359965e-05,
      "loss": 1.0109,
      "step": 77500
    },
    {
      "epoch": 1.39,
      "learning_rate": 3.0403048556361538e-05,
      "loss": 1.0007,
      "step": 78000
    },
    {
      "epoch": 1.4,
      "learning_rate": 3.0328034866363115e-05,
      "loss": 1.0048,
      "step": 78500
    },
    {
      "epoch": 1.41,
      "learning_rate": 3.0253021176364688e-05,
      "loss": 0.9977,
      "step": 79000
    },
    {
      "epoch": 1.42,
      "learning_rate": 3.0178007486366265e-05,
      "loss": 1.0177,
      "step": 79500
    },
    {
      "epoch": 1.43,
      "learning_rate": 3.0102993796367838e-05,
      "loss": 1.0066,
      "step": 80000
    },
    {
      "epoch": 1.43,
      "eval_accuracy": 0.7337787279529663,
      "eval_f1": 0.7314004197255196,
      "eval_loss": 0.7778696417808533,
      "eval_precision": 0.7351129951382487,
      "eval_recall": 0.7337787279529663,
      "eval_runtime": 265.4488,
      "eval_samples_per_second": 845.813,
      "eval_steps_per_second": 105.727,
      "step": 80000
    },
    {
      "epoch": 1.43,
      "learning_rate": 3.0027980106369418e-05,
      "loss": 1.0206,
      "step": 80500
    },
    {
      "epoch": 1.44,
      "learning_rate": 2.995296641637099e-05,
      "loss": 0.9937,
      "step": 81000
    },
    {
      "epoch": 1.45,
      "learning_rate": 2.9877952726372565e-05,
      "loss": 0.9974,
      "step": 81500
    },
    {
      "epoch": 1.46,
      "learning_rate": 2.980293903637414e-05,
      "loss": 0.9884,
      "step": 82000
    },
    {
      "epoch": 1.47,
      "learning_rate": 2.9727925346375715e-05,
      "loss": 0.9989,
      "step": 82500
    },
    {
      "epoch": 1.48,
      "learning_rate": 2.965291165637729e-05,
      "loss": 0.9993,
      "step": 83000
    },
    {
      "epoch": 1.49,
      "learning_rate": 2.9577897966378865e-05,
      "loss": 0.9943,
      "step": 83500
    },
    {
      "epoch": 1.5,
      "learning_rate": 2.9502884276380445e-05,
      "loss": 1.0188,
      "step": 84000
    },
    {
      "epoch": 1.51,
      "learning_rate": 2.942787058638202e-05,
      "loss": 0.9833,
      "step": 84500
    },
    {
      "epoch": 1.51,
      "learning_rate": 2.9352856896383592e-05,
      "loss": 1.0097,
      "step": 85000
    },
    {
      "epoch": 1.52,
      "learning_rate": 2.927784320638517e-05,
      "loss": 1.0022,
      "step": 85500
    },
    {
      "epoch": 1.53,
      "learning_rate": 2.9202829516386742e-05,
      "loss": 1.0079,
      "step": 86000
    },
    {
      "epoch": 1.54,
      "learning_rate": 2.912781582638832e-05,
      "loss": 0.9995,
      "step": 86500
    },
    {
      "epoch": 1.55,
      "learning_rate": 2.9052802136389892e-05,
      "loss": 1.0046,
      "step": 87000
    },
    {
      "epoch": 1.56,
      "learning_rate": 2.8977788446391472e-05,
      "loss": 1.01,
      "step": 87500
    },
    {
      "epoch": 1.57,
      "learning_rate": 2.8902774756393045e-05,
      "loss": 0.9976,
      "step": 88000
    },
    {
      "epoch": 1.58,
      "learning_rate": 2.882776106639462e-05,
      "loss": 0.9785,
      "step": 88500
    },
    {
      "epoch": 1.59,
      "learning_rate": 2.8752747376396195e-05,
      "loss": 0.9827,
      "step": 89000
    },
    {
      "epoch": 1.59,
      "learning_rate": 2.867773368639777e-05,
      "loss": 0.9979,
      "step": 89500
    },
    {
      "epoch": 1.6,
      "learning_rate": 2.8602719996399345e-05,
      "loss": 0.9896,
      "step": 90000
    },
    {
      "epoch": 1.61,
      "learning_rate": 2.852770630640092e-05,
      "loss": 1.0087,
      "step": 90500
    },
    {
      "epoch": 1.62,
      "learning_rate": 2.84526926164025e-05,
      "loss": 0.9968,
      "step": 91000
    },
    {
      "epoch": 1.63,
      "learning_rate": 2.8377678926404072e-05,
      "loss": 0.9934,
      "step": 91500
    },
    {
      "epoch": 1.64,
      "learning_rate": 2.8302665236405646e-05,
      "loss": 1.02,
      "step": 92000
    },
    {
      "epoch": 1.65,
      "learning_rate": 2.8227651546407222e-05,
      "loss": 1.0088,
      "step": 92500
    },
    {
      "epoch": 1.66,
      "learning_rate": 2.8152637856408796e-05,
      "loss": 0.9976,
      "step": 93000
    },
    {
      "epoch": 1.67,
      "learning_rate": 2.8077624166410372e-05,
      "loss": 0.9894,
      "step": 93500
    },
    {
      "epoch": 1.67,
      "learning_rate": 2.8002610476411946e-05,
      "loss": 0.9954,
      "step": 94000
    },
    {
      "epoch": 1.68,
      "learning_rate": 2.7927596786413526e-05,
      "loss": 0.9877,
      "step": 94500
    },
    {
      "epoch": 1.69,
      "learning_rate": 2.78525830964151e-05,
      "loss": 0.9964,
      "step": 95000
    },
    {
      "epoch": 1.7,
      "learning_rate": 2.7777569406416672e-05,
      "loss": 0.9872,
      "step": 95500
    },
    {
      "epoch": 1.71,
      "learning_rate": 2.770255571641825e-05,
      "loss": 0.9922,
      "step": 96000
    },
    {
      "epoch": 1.72,
      "learning_rate": 2.7627542026419823e-05,
      "loss": 1.0328,
      "step": 96500
    },
    {
      "epoch": 1.73,
      "learning_rate": 2.75525283364214e-05,
      "loss": 0.9937,
      "step": 97000
    },
    {
      "epoch": 1.74,
      "learning_rate": 2.7477514646422973e-05,
      "loss": 0.9853,
      "step": 97500
    },
    {
      "epoch": 1.75,
      "learning_rate": 2.7402500956424553e-05,
      "loss": 1.0054,
      "step": 98000
    },
    {
      "epoch": 1.75,
      "learning_rate": 2.7327487266426126e-05,
      "loss": 0.9888,
      "step": 98500
    },
    {
      "epoch": 1.76,
      "learning_rate": 2.72524735764277e-05,
      "loss": 1.0035,
      "step": 99000
    },
    {
      "epoch": 1.77,
      "learning_rate": 2.7177459886429276e-05,
      "loss": 1.0045,
      "step": 99500
    },
    {
      "epoch": 1.78,
      "learning_rate": 2.710244619643085e-05,
      "loss": 0.9906,
      "step": 100000
    },
    {
      "epoch": 1.78,
      "eval_accuracy": 0.7485836451095671,
      "eval_f1": 0.7465735077247584,
      "eval_loss": 0.7205876708030701,
      "eval_precision": 0.7490934890407157,
      "eval_recall": 0.7485836451095671,
      "eval_runtime": 263.2948,
      "eval_samples_per_second": 852.732,
      "eval_steps_per_second": 106.592,
      "step": 100000
    },
    {
      "epoch": 1.79,
      "learning_rate": 2.7027432506432426e-05,
      "loss": 0.9907,
      "step": 100500
    },
    {
      "epoch": 1.8,
      "learning_rate": 2.6952418816434e-05,
      "loss": 0.9772,
      "step": 101000
    },
    {
      "epoch": 1.81,
      "learning_rate": 2.687740512643558e-05,
      "loss": 0.9846,
      "step": 101500
    },
    {
      "epoch": 1.82,
      "learning_rate": 2.6802391436437153e-05,
      "loss": 0.9877,
      "step": 102000
    },
    {
      "epoch": 1.83,
      "learning_rate": 2.6727377746438726e-05,
      "loss": 1.0153,
      "step": 102500
    },
    {
      "epoch": 1.84,
      "learning_rate": 2.6652364056440303e-05,
      "loss": 0.9911,
      "step": 103000
    },
    {
      "epoch": 1.84,
      "learning_rate": 2.6577350366441876e-05,
      "loss": 0.9892,
      "step": 103500
    },
    {
      "epoch": 1.85,
      "learning_rate": 2.6502336676443453e-05,
      "loss": 1.0009,
      "step": 104000
    },
    {
      "epoch": 1.86,
      "learning_rate": 2.6427322986445026e-05,
      "loss": 1.0071,
      "step": 104500
    },
    {
      "epoch": 1.87,
      "learning_rate": 2.6352309296446607e-05,
      "loss": 0.9815,
      "step": 105000
    },
    {
      "epoch": 1.88,
      "learning_rate": 2.627729560644818e-05,
      "loss": 0.9971,
      "step": 105500
    },
    {
      "epoch": 1.89,
      "learning_rate": 2.6202281916449753e-05,
      "loss": 0.9726,
      "step": 106000
    },
    {
      "epoch": 1.9,
      "learning_rate": 2.612726822645133e-05,
      "loss": 0.9913,
      "step": 106500
    },
    {
      "epoch": 1.91,
      "learning_rate": 2.6052254536452903e-05,
      "loss": 0.9983,
      "step": 107000
    },
    {
      "epoch": 1.92,
      "learning_rate": 2.597724084645448e-05,
      "loss": 0.9805,
      "step": 107500
    },
    {
      "epoch": 1.92,
      "learning_rate": 2.5902227156456053e-05,
      "loss": 0.987,
      "step": 108000
    },
    {
      "epoch": 1.93,
      "learning_rate": 2.5827213466457633e-05,
      "loss": 1.0004,
      "step": 108500
    },
    {
      "epoch": 1.94,
      "learning_rate": 2.5752199776459207e-05,
      "loss": 1.0028,
      "step": 109000
    },
    {
      "epoch": 1.95,
      "learning_rate": 2.567718608646078e-05,
      "loss": 0.9795,
      "step": 109500
    },
    {
      "epoch": 1.96,
      "learning_rate": 2.5602172396462357e-05,
      "loss": 0.9829,
      "step": 110000
    },
    {
      "epoch": 1.97,
      "learning_rate": 2.552715870646393e-05,
      "loss": 0.995,
      "step": 110500
    },
    {
      "epoch": 1.98,
      "learning_rate": 2.5452145016465507e-05,
      "loss": 0.9925,
      "step": 111000
    },
    {
      "epoch": 1.99,
      "learning_rate": 2.537713132646708e-05,
      "loss": 0.993,
      "step": 111500
    },
    {
      "epoch": 2.0,
      "learning_rate": 2.530211763646866e-05,
      "loss": 0.994,
      "step": 112000
    },
    {
      "epoch": 2.0,
      "learning_rate": 2.5227103946470234e-05,
      "loss": 0.9164,
      "step": 112500
    },
    {
      "epoch": 2.01,
      "learning_rate": 2.5152090256471807e-05,
      "loss": 0.8751,
      "step": 113000
    },
    {
      "epoch": 2.02,
      "learning_rate": 2.5077076566473384e-05,
      "loss": 0.8783,
      "step": 113500
    },
    {
      "epoch": 2.03,
      "learning_rate": 2.5002062876474957e-05,
      "loss": 0.8483,
      "step": 114000
    },
    {
      "epoch": 2.04,
      "learning_rate": 2.4927049186476534e-05,
      "loss": 0.8871,
      "step": 114500
    },
    {
      "epoch": 2.05,
      "learning_rate": 2.4852035496478107e-05,
      "loss": 0.8571,
      "step": 115000
    },
    {
      "epoch": 2.06,
      "learning_rate": 2.4777021806479687e-05,
      "loss": 0.8798,
      "step": 115500
    },
    {
      "epoch": 2.07,
      "learning_rate": 2.470200811648126e-05,
      "loss": 0.8587,
      "step": 116000
    },
    {
      "epoch": 2.08,
      "learning_rate": 2.4626994426482834e-05,
      "loss": 0.8736,
      "step": 116500
    },
    {
      "epoch": 2.08,
      "learning_rate": 2.455198073648441e-05,
      "loss": 0.8704,
      "step": 117000
    },
    {
      "epoch": 2.09,
      "learning_rate": 2.4476967046485984e-05,
      "loss": 0.8764,
      "step": 117500
    },
    {
      "epoch": 2.1,
      "learning_rate": 2.440195335648756e-05,
      "loss": 0.8665,
      "step": 118000
    },
    {
      "epoch": 2.11,
      "learning_rate": 2.4326939666489134e-05,
      "loss": 0.8652,
      "step": 118500
    },
    {
      "epoch": 2.12,
      "learning_rate": 2.4251925976490714e-05,
      "loss": 0.8741,
      "step": 119000
    },
    {
      "epoch": 2.13,
      "learning_rate": 2.4176912286492288e-05,
      "loss": 0.892,
      "step": 119500
    },
    {
      "epoch": 2.14,
      "learning_rate": 2.410189859649386e-05,
      "loss": 0.8795,
      "step": 120000
    },
    {
      "epoch": 2.14,
      "eval_accuracy": 0.7461874220559416,
      "eval_f1": 0.7435782642254625,
      "eval_loss": 0.785278856754303,
      "eval_precision": 0.7461997723795062,
      "eval_recall": 0.7461874220559416,
      "eval_runtime": 266.0304,
      "eval_samples_per_second": 843.964,
      "eval_steps_per_second": 105.495,
      "step": 120000
    },
    {
      "epoch": 2.15,
      "learning_rate": 2.4026884906495438e-05,
      "loss": 0.8767,
      "step": 120500
    },
    {
      "epoch": 2.16,
      "learning_rate": 2.395187121649701e-05,
      "loss": 0.8711,
      "step": 121000
    },
    {
      "epoch": 2.16,
      "learning_rate": 2.3876857526498588e-05,
      "loss": 0.8658,
      "step": 121500
    },
    {
      "epoch": 2.17,
      "learning_rate": 2.380184383650016e-05,
      "loss": 0.8798,
      "step": 122000
    },
    {
      "epoch": 2.18,
      "learning_rate": 2.372683014650174e-05,
      "loss": 0.8775,
      "step": 122500
    },
    {
      "epoch": 2.19,
      "learning_rate": 2.3651816456503314e-05,
      "loss": 0.8816,
      "step": 123000
    },
    {
      "epoch": 2.2,
      "learning_rate": 2.3576802766504888e-05,
      "loss": 0.8584,
      "step": 123500
    },
    {
      "epoch": 2.21,
      "learning_rate": 2.3501789076506465e-05,
      "loss": 0.8871,
      "step": 124000
    },
    {
      "epoch": 2.22,
      "learning_rate": 2.3426775386508038e-05,
      "loss": 0.8891,
      "step": 124500
    },
    {
      "epoch": 2.23,
      "learning_rate": 2.3351761696509615e-05,
      "loss": 0.8866,
      "step": 125000
    },
    {
      "epoch": 2.24,
      "learning_rate": 2.3276748006511188e-05,
      "loss": 0.8675,
      "step": 125500
    },
    {
      "epoch": 2.24,
      "learning_rate": 2.3201734316512768e-05,
      "loss": 0.8899,
      "step": 126000
    },
    {
      "epoch": 2.25,
      "learning_rate": 2.312672062651434e-05,
      "loss": 0.8516,
      "step": 126500
    },
    {
      "epoch": 2.26,
      "learning_rate": 2.3051706936515915e-05,
      "loss": 0.8714,
      "step": 127000
    },
    {
      "epoch": 2.27,
      "learning_rate": 2.297669324651749e-05,
      "loss": 0.8775,
      "step": 127500
    },
    {
      "epoch": 2.28,
      "learning_rate": 2.2901679556519065e-05,
      "loss": 0.8661,
      "step": 128000
    },
    {
      "epoch": 2.29,
      "learning_rate": 2.282666586652064e-05,
      "loss": 0.8837,
      "step": 128500
    },
    {
      "epoch": 2.3,
      "learning_rate": 2.2751652176522215e-05,
      "loss": 0.8778,
      "step": 129000
    },
    {
      "epoch": 2.31,
      "learning_rate": 2.2676638486523795e-05,
      "loss": 0.8687,
      "step": 129500
    },
    {
      "epoch": 2.32,
      "learning_rate": 2.2601624796525368e-05,
      "loss": 0.8988,
      "step": 130000
    },
    {
      "epoch": 2.32,
      "learning_rate": 2.252661110652694e-05,
      "loss": 0.8871,
      "step": 130500
    },
    {
      "epoch": 2.33,
      "learning_rate": 2.245159741652852e-05,
      "loss": 0.8595,
      "step": 131000
    },
    {
      "epoch": 2.34,
      "learning_rate": 2.237658372653009e-05,
      "loss": 0.8864,
      "step": 131500
    },
    {
      "epoch": 2.35,
      "learning_rate": 2.230157003653167e-05,
      "loss": 0.8846,
      "step": 132000
    },
    {
      "epoch": 2.36,
      "learning_rate": 2.2226556346533245e-05,
      "loss": 0.8711,
      "step": 132500
    },
    {
      "epoch": 2.37,
      "learning_rate": 2.2151542656534822e-05,
      "loss": 0.8958,
      "step": 133000
    },
    {
      "epoch": 2.38,
      "learning_rate": 2.2076528966536395e-05,
      "loss": 0.8882,
      "step": 133500
    },
    {
      "epoch": 2.39,
      "learning_rate": 2.200151527653797e-05,
      "loss": 0.8671,
      "step": 134000
    },
    {
      "epoch": 2.4,
      "learning_rate": 2.1926501586539545e-05,
      "loss": 0.8757,
      "step": 134500
    },
    {
      "epoch": 2.41,
      "learning_rate": 2.185148789654112e-05,
      "loss": 0.8847,
      "step": 135000
    },
    {
      "epoch": 2.41,
      "learning_rate": 2.17764742065427e-05,
      "loss": 0.8682,
      "step": 135500
    },
    {
      "epoch": 2.42,
      "learning_rate": 2.1701460516544272e-05,
      "loss": 0.8713,
      "step": 136000
    },
    {
      "epoch": 2.43,
      "learning_rate": 2.162644682654585e-05,
      "loss": 0.8785,
      "step": 136500
    },
    {
      "epoch": 2.44,
      "learning_rate": 2.1551433136547422e-05,
      "loss": 0.8854,
      "step": 137000
    },
    {
      "epoch": 2.45,
      "learning_rate": 2.1476419446548995e-05,
      "loss": 0.8841,
      "step": 137500
    },
    {
      "epoch": 2.46,
      "learning_rate": 2.1401405756550572e-05,
      "loss": 0.8899,
      "step": 138000
    },
    {
      "epoch": 2.47,
      "learning_rate": 2.1326392066552145e-05,
      "loss": 0.8739,
      "step": 138500
    },
    {
      "epoch": 2.48,
      "learning_rate": 2.1251378376553726e-05,
      "loss": 0.8815,
      "step": 139000
    },
    {
      "epoch": 2.49,
      "learning_rate": 2.11763646865553e-05,
      "loss": 0.8657,
      "step": 139500
    },
    {
      "epoch": 2.49,
      "learning_rate": 2.1101350996556876e-05,
      "loss": 0.87,
      "step": 140000
    },
    {
      "epoch": 2.49,
      "eval_accuracy": 0.7493987172634955,
      "eval_f1": 0.7460943073701467,
      "eval_loss": 0.7765525579452515,
      "eval_precision": 0.7486864579533199,
      "eval_recall": 0.7493987172634955,
      "eval_runtime": 264.1677,
      "eval_samples_per_second": 849.915,
      "eval_steps_per_second": 106.239,
      "step": 140000
    },
    {
      "epoch": 2.5,
      "learning_rate": 2.102633730655845e-05,
      "loss": 0.8886,
      "step": 140500
    },
    {
      "epoch": 2.51,
      "learning_rate": 2.0951323616560022e-05,
      "loss": 0.8737,
      "step": 141000
    },
    {
      "epoch": 2.52,
      "learning_rate": 2.08763099265616e-05,
      "loss": 0.8838,
      "step": 141500
    },
    {
      "epoch": 2.53,
      "learning_rate": 2.0801296236563172e-05,
      "loss": 0.8442,
      "step": 142000
    },
    {
      "epoch": 2.54,
      "learning_rate": 2.0726282546564753e-05,
      "loss": 0.8838,
      "step": 142500
    },
    {
      "epoch": 2.55,
      "learning_rate": 2.0651268856566326e-05,
      "loss": 0.876,
      "step": 143000
    },
    {
      "epoch": 2.56,
      "learning_rate": 2.0576255166567903e-05,
      "loss": 0.872,
      "step": 143500
    },
    {
      "epoch": 2.57,
      "learning_rate": 2.0501241476569476e-05,
      "loss": 0.8844,
      "step": 144000
    },
    {
      "epoch": 2.57,
      "learning_rate": 2.042622778657105e-05,
      "loss": 0.8806,
      "step": 144500
    },
    {
      "epoch": 2.58,
      "learning_rate": 2.0351214096572626e-05,
      "loss": 0.9131,
      "step": 145000
    },
    {
      "epoch": 2.59,
      "learning_rate": 2.02762004065742e-05,
      "loss": 0.8669,
      "step": 145500
    },
    {
      "epoch": 2.6,
      "learning_rate": 2.020118671657578e-05,
      "loss": 0.886,
      "step": 146000
    },
    {
      "epoch": 2.61,
      "learning_rate": 2.0126173026577353e-05,
      "loss": 0.8827,
      "step": 146500
    },
    {
      "epoch": 2.62,
      "learning_rate": 2.005115933657893e-05,
      "loss": 0.8739,
      "step": 147000
    },
    {
      "epoch": 2.63,
      "learning_rate": 1.9976145646580503e-05,
      "loss": 0.8799,
      "step": 147500
    },
    {
      "epoch": 2.64,
      "learning_rate": 1.990113195658208e-05,
      "loss": 0.8697,
      "step": 148000
    },
    {
      "epoch": 2.65,
      "learning_rate": 1.9826118266583653e-05,
      "loss": 0.8757,
      "step": 148500
    },
    {
      "epoch": 2.65,
      "learning_rate": 1.975110457658523e-05,
      "loss": 0.8953,
      "step": 149000
    },
    {
      "epoch": 2.66,
      "learning_rate": 1.9676090886586803e-05,
      "loss": 0.8792,
      "step": 149500
    },
    {
      "epoch": 2.67,
      "learning_rate": 1.960107719658838e-05,
      "loss": 0.8739,
      "step": 150000
    },
    {
      "epoch": 2.68,
      "learning_rate": 1.9526063506589953e-05,
      "loss": 0.8912,
      "step": 150500
    },
    {
      "epoch": 2.69,
      "learning_rate": 1.945104981659153e-05,
      "loss": 0.8803,
      "step": 151000
    },
    {
      "epoch": 2.7,
      "learning_rate": 1.9376036126593106e-05,
      "loss": 0.896,
      "step": 151500
    },
    {
      "epoch": 2.71,
      "learning_rate": 1.930102243659468e-05,
      "loss": 0.8701,
      "step": 152000
    },
    {
      "epoch": 2.72,
      "learning_rate": 1.9226008746596257e-05,
      "loss": 0.8983,
      "step": 152500
    },
    {
      "epoch": 2.73,
      "learning_rate": 1.915099505659783e-05,
      "loss": 0.8885,
      "step": 153000
    },
    {
      "epoch": 2.73,
      "learning_rate": 1.9075981366599407e-05,
      "loss": 0.8848,
      "step": 153500
    },
    {
      "epoch": 2.74,
      "learning_rate": 1.900096767660098e-05,
      "loss": 0.8883,
      "step": 154000
    },
    {
      "epoch": 2.75,
      "learning_rate": 1.8925953986602557e-05,
      "loss": 0.8617,
      "step": 154500
    },
    {
      "epoch": 2.76,
      "learning_rate": 1.8850940296604133e-05,
      "loss": 0.8781,
      "step": 155000
    },
    {
      "epoch": 2.77,
      "learning_rate": 1.8775926606605707e-05,
      "loss": 0.882,
      "step": 155500
    },
    {
      "epoch": 2.78,
      "learning_rate": 1.8700912916607283e-05,
      "loss": 0.8878,
      "step": 156000
    },
    {
      "epoch": 2.79,
      "learning_rate": 1.8625899226608857e-05,
      "loss": 0.8872,
      "step": 156500
    },
    {
      "epoch": 2.8,
      "learning_rate": 1.8550885536610434e-05,
      "loss": 0.8668,
      "step": 157000
    },
    {
      "epoch": 2.81,
      "learning_rate": 1.8475871846612007e-05,
      "loss": 0.8741,
      "step": 157500
    },
    {
      "epoch": 2.81,
      "learning_rate": 1.8400858156613584e-05,
      "loss": 0.8989,
      "step": 158000
    },
    {
      "epoch": 2.82,
      "learning_rate": 1.832584446661516e-05,
      "loss": 0.8826,
      "step": 158500
    },
    {
      "epoch": 2.83,
      "learning_rate": 1.8250830776616734e-05,
      "loss": 0.8644,
      "step": 159000
    },
    {
      "epoch": 2.84,
      "learning_rate": 1.817581708661831e-05,
      "loss": 0.8684,
      "step": 159500
    },
    {
      "epoch": 2.85,
      "learning_rate": 1.8100803396619884e-05,
      "loss": 0.8909,
      "step": 160000
    },
    {
      "epoch": 2.85,
      "eval_accuracy": 0.7561642615357207,
      "eval_f1": 0.7529456090776351,
      "eval_loss": 0.7471145391464233,
      "eval_precision": 0.7561614537137438,
      "eval_recall": 0.7561642615357207,
      "eval_runtime": 267.483,
      "eval_samples_per_second": 839.381,
      "eval_steps_per_second": 104.923,
      "step": 160000
    },
    {
      "epoch": 2.86,
      "learning_rate": 1.802578970662146e-05,
      "loss": 0.9022,
      "step": 160500
    },
    {
      "epoch": 2.87,
      "learning_rate": 1.7950776016623034e-05,
      "loss": 0.8733,
      "step": 161000
    },
    {
      "epoch": 2.88,
      "learning_rate": 1.787576232662461e-05,
      "loss": 0.8821,
      "step": 161500
    },
    {
      "epoch": 2.89,
      "learning_rate": 1.7800748636626187e-05,
      "loss": 0.9022,
      "step": 162000
    },
    {
      "epoch": 2.9,
      "learning_rate": 1.772573494662776e-05,
      "loss": 0.8636,
      "step": 162500
    },
    {
      "epoch": 2.9,
      "learning_rate": 1.7650721256629337e-05,
      "loss": 0.8754,
      "step": 163000
    },
    {
      "epoch": 2.91,
      "learning_rate": 1.757570756663091e-05,
      "loss": 0.8728,
      "step": 163500
    },
    {
      "epoch": 2.92,
      "learning_rate": 1.7500693876632487e-05,
      "loss": 0.8689,
      "step": 164000
    },
    {
      "epoch": 2.93,
      "learning_rate": 1.742568018663406e-05,
      "loss": 0.8713,
      "step": 164500
    },
    {
      "epoch": 2.94,
      "learning_rate": 1.7350666496635637e-05,
      "loss": 0.8857,
      "step": 165000
    },
    {
      "epoch": 2.95,
      "learning_rate": 1.7275652806637214e-05,
      "loss": 0.8739,
      "step": 165500
    },
    {
      "epoch": 2.96,
      "learning_rate": 1.7200639116638787e-05,
      "loss": 0.8692,
      "step": 166000
    },
    {
      "epoch": 2.97,
      "learning_rate": 1.7125625426640364e-05,
      "loss": 0.8913,
      "step": 166500
    },
    {
      "epoch": 2.98,
      "learning_rate": 1.7050611736641938e-05,
      "loss": 0.8885,
      "step": 167000
    },
    {
      "epoch": 2.98,
      "learning_rate": 1.6975598046643514e-05,
      "loss": 0.8863,
      "step": 167500
    },
    {
      "epoch": 2.99,
      "learning_rate": 1.6900584356645088e-05,
      "loss": 0.872,
      "step": 168000
    },
    {
      "epoch": 3.0,
      "learning_rate": 1.6825570666646664e-05,
      "loss": 0.8564,
      "step": 168500
    },
    {
      "epoch": 3.01,
      "learning_rate": 1.675055697664824e-05,
      "loss": 0.7672,
      "step": 169000
    },
    {
      "epoch": 3.02,
      "learning_rate": 1.6675543286649814e-05,
      "loss": 0.7399,
      "step": 169500
    },
    {
      "epoch": 3.03,
      "learning_rate": 1.660052959665139e-05,
      "loss": 0.762,
      "step": 170000
    },
    {
      "epoch": 3.04,
      "learning_rate": 1.6525515906652964e-05,
      "loss": 0.7586,
      "step": 170500
    },
    {
      "epoch": 3.05,
      "learning_rate": 1.645050221665454e-05,
      "loss": 0.7396,
      "step": 171000
    },
    {
      "epoch": 3.06,
      "learning_rate": 1.6375488526656115e-05,
      "loss": 0.7469,
      "step": 171500
    },
    {
      "epoch": 3.06,
      "learning_rate": 1.630047483665769e-05,
      "loss": 0.7545,
      "step": 172000
    },
    {
      "epoch": 3.07,
      "learning_rate": 1.6225461146659268e-05,
      "loss": 0.7409,
      "step": 172500
    },
    {
      "epoch": 3.08,
      "learning_rate": 1.615044745666084e-05,
      "loss": 0.741,
      "step": 173000
    },
    {
      "epoch": 3.09,
      "learning_rate": 1.6075433766662418e-05,
      "loss": 0.7539,
      "step": 173500
    },
    {
      "epoch": 3.1,
      "learning_rate": 1.600042007666399e-05,
      "loss": 0.735,
      "step": 174000
    },
    {
      "epoch": 3.11,
      "learning_rate": 1.5925406386665568e-05,
      "loss": 0.7621,
      "step": 174500
    },
    {
      "epoch": 3.12,
      "learning_rate": 1.585039269666714e-05,
      "loss": 0.78,
      "step": 175000
    },
    {
      "epoch": 3.13,
      "learning_rate": 1.5775379006668718e-05,
      "loss": 0.7325,
      "step": 175500
    },
    {
      "epoch": 3.14,
      "learning_rate": 1.5700365316670295e-05,
      "loss": 0.7597,
      "step": 176000
    },
    {
      "epoch": 3.14,
      "learning_rate": 1.5625351626671868e-05,
      "loss": 0.7422,
      "step": 176500
    },
    {
      "epoch": 3.15,
      "learning_rate": 1.5550337936673445e-05,
      "loss": 0.759,
      "step": 177000
    },
    {
      "epoch": 3.16,
      "learning_rate": 1.5475324246675018e-05,
      "loss": 0.7443,
      "step": 177500
    },
    {
      "epoch": 3.17,
      "learning_rate": 1.5400310556676595e-05,
      "loss": 0.7595,
      "step": 178000
    },
    {
      "epoch": 3.18,
      "learning_rate": 1.532529686667817e-05,
      "loss": 0.7643,
      "step": 178500
    },
    {
      "epoch": 3.19,
      "learning_rate": 1.5250283176679745e-05,
      "loss": 0.7447,
      "step": 179000
    },
    {
      "epoch": 3.2,
      "learning_rate": 1.5175269486681322e-05,
      "loss": 0.7498,
      "step": 179500
    },
    {
      "epoch": 3.21,
      "learning_rate": 1.5100255796682897e-05,
      "loss": 0.7573,
      "step": 180000
    },
    {
      "epoch": 3.21,
      "eval_accuracy": 0.755656511669339,
      "eval_f1": 0.7533397160721758,
      "eval_loss": 0.8454098701477051,
      "eval_precision": 0.7553010606993256,
      "eval_recall": 0.755656511669339,
      "eval_runtime": 292.5825,
      "eval_samples_per_second": 767.373,
      "eval_steps_per_second": 95.922,
      "step": 180000
    },
    {
      "epoch": 3.22,
      "learning_rate": 1.5025242106684472e-05,
      "loss": 0.7713,
      "step": 180500
    },
    {
      "epoch": 3.22,
      "learning_rate": 1.4950228416686045e-05,
      "loss": 0.7408,
      "step": 181000
    },
    {
      "epoch": 3.23,
      "learning_rate": 1.4875214726687622e-05,
      "loss": 0.7662,
      "step": 181500
    },
    {
      "epoch": 3.24,
      "learning_rate": 1.4800201036689197e-05,
      "loss": 0.7648,
      "step": 182000
    },
    {
      "epoch": 3.25,
      "learning_rate": 1.4725187346690772e-05,
      "loss": 0.742,
      "step": 182500
    },
    {
      "epoch": 3.26,
      "learning_rate": 1.4650173656692349e-05,
      "loss": 0.7604,
      "step": 183000
    },
    {
      "epoch": 3.27,
      "learning_rate": 1.4575159966693924e-05,
      "loss": 0.7633,
      "step": 183500
    },
    {
      "epoch": 3.28,
      "learning_rate": 1.4500146276695497e-05,
      "loss": 0.7676,
      "step": 184000
    },
    {
      "epoch": 3.29,
      "learning_rate": 1.4425132586697072e-05,
      "loss": 0.7579,
      "step": 184500
    },
    {
      "epoch": 3.3,
      "learning_rate": 1.4350118896698649e-05,
      "loss": 0.7596,
      "step": 185000
    },
    {
      "epoch": 3.3,
      "learning_rate": 1.4275105206700224e-05,
      "loss": 0.7471,
      "step": 185500
    },
    {
      "epoch": 3.31,
      "learning_rate": 1.4200091516701799e-05,
      "loss": 0.7681,
      "step": 186000
    },
    {
      "epoch": 3.32,
      "learning_rate": 1.4125077826703376e-05,
      "loss": 0.7599,
      "step": 186500
    },
    {
      "epoch": 3.33,
      "learning_rate": 1.405006413670495e-05,
      "loss": 0.7548,
      "step": 187000
    },
    {
      "epoch": 3.34,
      "learning_rate": 1.3975050446706524e-05,
      "loss": 0.7641,
      "step": 187500
    },
    {
      "epoch": 3.35,
      "learning_rate": 1.3900036756708099e-05,
      "loss": 0.7723,
      "step": 188000
    },
    {
      "epoch": 3.36,
      "learning_rate": 1.3825023066709676e-05,
      "loss": 0.7456,
      "step": 188500
    },
    {
      "epoch": 3.37,
      "learning_rate": 1.375000937671125e-05,
      "loss": 0.7595,
      "step": 189000
    },
    {
      "epoch": 3.38,
      "learning_rate": 1.3674995686712826e-05,
      "loss": 0.7662,
      "step": 189500
    },
    {
      "epoch": 3.38,
      "learning_rate": 1.3599981996714403e-05,
      "loss": 0.7584,
      "step": 190000
    },
    {
      "epoch": 3.39,
      "learning_rate": 1.3524968306715978e-05,
      "loss": 0.7504,
      "step": 190500
    },
    {
      "epoch": 3.4,
      "learning_rate": 1.3449954616717551e-05,
      "loss": 0.7537,
      "step": 191000
    },
    {
      "epoch": 3.41,
      "learning_rate": 1.3374940926719126e-05,
      "loss": 0.7696,
      "step": 191500
    },
    {
      "epoch": 3.42,
      "learning_rate": 1.3299927236720703e-05,
      "loss": 0.7522,
      "step": 192000
    },
    {
      "epoch": 3.43,
      "learning_rate": 1.3224913546722278e-05,
      "loss": 0.7471,
      "step": 192500
    },
    {
      "epoch": 3.44,
      "learning_rate": 1.3149899856723853e-05,
      "loss": 0.7643,
      "step": 193000
    },
    {
      "epoch": 3.45,
      "learning_rate": 1.307488616672543e-05,
      "loss": 0.7564,
      "step": 193500
    },
    {
      "epoch": 3.46,
      "learning_rate": 1.2999872476727005e-05,
      "loss": 0.76,
      "step": 194000
    },
    {
      "epoch": 3.47,
      "learning_rate": 1.2924858786728578e-05,
      "loss": 0.764,
      "step": 194500
    },
    {
      "epoch": 3.47,
      "learning_rate": 1.2849845096730153e-05,
      "loss": 0.7474,
      "step": 195000
    },
    {
      "epoch": 3.48,
      "learning_rate": 1.277483140673173e-05,
      "loss": 0.7667,
      "step": 195500
    },
    {
      "epoch": 3.49,
      "learning_rate": 1.2699817716733305e-05,
      "loss": 0.7419,
      "step": 196000
    },
    {
      "epoch": 3.5,
      "learning_rate": 1.262480402673488e-05,
      "loss": 0.7686,
      "step": 196500
    },
    {
      "epoch": 3.51,
      "learning_rate": 1.2549790336736456e-05,
      "loss": 0.7635,
      "step": 197000
    },
    {
      "epoch": 3.52,
      "learning_rate": 1.2474776646738031e-05,
      "loss": 0.766,
      "step": 197500
    },
    {
      "epoch": 3.53,
      "learning_rate": 1.2399762956739605e-05,
      "loss": 0.7627,
      "step": 198000
    },
    {
      "epoch": 3.54,
      "learning_rate": 1.232474926674118e-05,
      "loss": 0.7447,
      "step": 198500
    },
    {
      "epoch": 3.55,
      "learning_rate": 1.2249735576742757e-05,
      "loss": 0.7498,
      "step": 199000
    },
    {
      "epoch": 3.55,
      "learning_rate": 1.2174721886744332e-05,
      "loss": 0.7726,
      "step": 199500
    },
    {
      "epoch": 3.56,
      "learning_rate": 1.2099708196745907e-05,
      "loss": 0.7741,
      "step": 200000
    },
    {
      "epoch": 3.56,
      "eval_accuracy": 0.7581373597006948,
      "eval_f1": 0.7562878270255092,
      "eval_loss": 0.8467927575111389,
      "eval_precision": 0.758636987154856,
      "eval_recall": 0.7581373597006948,
      "eval_runtime": 227.8586,
      "eval_samples_per_second": 985.348,
      "eval_steps_per_second": 123.169,
      "step": 200000
    },
    {
      "epoch": 3.57,
      "learning_rate": 1.2024694506747483e-05,
      "loss": 0.7541,
      "step": 200500
    },
    {
      "epoch": 3.58,
      "learning_rate": 1.1949680816749058e-05,
      "loss": 0.7656,
      "step": 201000
    },
    {
      "epoch": 3.59,
      "learning_rate": 1.1874667126750632e-05,
      "loss": 0.7735,
      "step": 201500
    },
    {
      "epoch": 3.6,
      "learning_rate": 1.1799653436752207e-05,
      "loss": 0.7621,
      "step": 202000
    },
    {
      "epoch": 3.61,
      "learning_rate": 1.1724639746753783e-05,
      "loss": 0.76,
      "step": 202500
    },
    {
      "epoch": 3.62,
      "learning_rate": 1.1649626056755358e-05,
      "loss": 0.7486,
      "step": 203000
    },
    {
      "epoch": 3.63,
      "learning_rate": 1.1574612366756935e-05,
      "loss": 0.7469,
      "step": 203500
    },
    {
      "epoch": 3.63,
      "learning_rate": 1.149959867675851e-05,
      "loss": 0.7617,
      "step": 204000
    },
    {
      "epoch": 3.64,
      "learning_rate": 1.1424584986760085e-05,
      "loss": 0.7575,
      "step": 204500
    },
    {
      "epoch": 3.65,
      "learning_rate": 1.1349571296761659e-05,
      "loss": 0.759,
      "step": 205000
    },
    {
      "epoch": 3.66,
      "learning_rate": 1.1274557606763235e-05,
      "loss": 0.752,
      "step": 205500
    },
    {
      "epoch": 3.67,
      "learning_rate": 1.119954391676481e-05,
      "loss": 0.7647,
      "step": 206000
    },
    {
      "epoch": 3.68,
      "learning_rate": 1.1124530226766385e-05,
      "loss": 0.7553,
      "step": 206500
    },
    {
      "epoch": 3.69,
      "learning_rate": 1.1049516536767962e-05,
      "loss": 0.7598,
      "step": 207000
    },
    {
      "epoch": 3.7,
      "learning_rate": 1.0974502846769537e-05,
      "loss": 0.7474,
      "step": 207500
    },
    {
      "epoch": 3.71,
      "learning_rate": 1.0899489156771112e-05,
      "loss": 0.7693,
      "step": 208000
    },
    {
      "epoch": 3.71,
      "learning_rate": 1.0824475466772686e-05,
      "loss": 0.7493,
      "step": 208500
    },
    {
      "epoch": 3.72,
      "learning_rate": 1.0749461776774262e-05,
      "loss": 0.7595,
      "step": 209000
    },
    {
      "epoch": 3.73,
      "learning_rate": 1.0674448086775837e-05,
      "loss": 0.7556,
      "step": 209500
    },
    {
      "epoch": 3.74,
      "learning_rate": 1.0599434396777412e-05,
      "loss": 0.7677,
      "step": 210000
    },
    {
      "epoch": 3.75,
      "learning_rate": 1.0524420706778989e-05,
      "loss": 0.7579,
      "step": 210500
    },
    {
      "epoch": 3.76,
      "learning_rate": 1.0449407016780564e-05,
      "loss": 0.7676,
      "step": 211000
    },
    {
      "epoch": 3.77,
      "learning_rate": 1.0374393326782139e-05,
      "loss": 0.7374,
      "step": 211500
    },
    {
      "epoch": 3.78,
      "learning_rate": 1.0299379636783712e-05,
      "loss": 0.7605,
      "step": 212000
    },
    {
      "epoch": 3.79,
      "learning_rate": 1.0224365946785289e-05,
      "loss": 0.7407,
      "step": 212500
    },
    {
      "epoch": 3.79,
      "learning_rate": 1.0149352256786864e-05,
      "loss": 0.7516,
      "step": 213000
    },
    {
      "epoch": 3.8,
      "learning_rate": 1.007433856678844e-05,
      "loss": 0.7616,
      "step": 213500
    },
    {
      "epoch": 3.81,
      "learning_rate": 9.999324876790016e-06,
      "loss": 0.7564,
      "step": 214000
    },
    {
      "epoch": 3.82,
      "learning_rate": 9.92431118679159e-06,
      "loss": 0.7575,
      "step": 214500
    },
    {
      "epoch": 3.83,
      "learning_rate": 9.849297496793166e-06,
      "loss": 0.7711,
      "step": 215000
    },
    {
      "epoch": 3.84,
      "learning_rate": 9.774283806794741e-06,
      "loss": 0.7635,
      "step": 215500
    },
    {
      "epoch": 3.85,
      "learning_rate": 9.699270116796316e-06,
      "loss": 0.7706,
      "step": 216000
    },
    {
      "epoch": 3.86,
      "learning_rate": 9.624256426797891e-06,
      "loss": 0.7425,
      "step": 216500
    },
    {
      "epoch": 3.87,
      "learning_rate": 9.549242736799466e-06,
      "loss": 0.7496,
      "step": 217000
    },
    {
      "epoch": 3.87,
      "learning_rate": 9.474229046801043e-06,
      "loss": 0.7496,
      "step": 217500
    },
    {
      "epoch": 3.88,
      "learning_rate": 9.399215356802616e-06,
      "loss": 0.743,
      "step": 218000
    },
    {
      "epoch": 3.89,
      "learning_rate": 9.324201666804193e-06,
      "loss": 0.7509,
      "step": 218500
    },
    {
      "epoch": 3.9,
      "learning_rate": 9.249187976805768e-06,
      "loss": 0.7622,
      "step": 219000
    },
    {
      "epoch": 3.91,
      "learning_rate": 9.174174286807343e-06,
      "loss": 0.7595,
      "step": 219500
    },
    {
      "epoch": 3.92,
      "learning_rate": 9.099160596808918e-06,
      "loss": 0.7613,
      "step": 220000
    },
    {
      "epoch": 3.92,
      "eval_accuracy": 0.7602975236059148,
      "eval_f1": 0.7589917045485225,
      "eval_loss": 0.8300805687904358,
      "eval_precision": 0.7602088665110927,
      "eval_recall": 0.7602975236059148,
      "eval_runtime": 225.3822,
      "eval_samples_per_second": 996.174,
      "eval_steps_per_second": 124.522,
      "step": 220000
    }
  ],
  "max_steps": 280650,
  "num_train_epochs": 5,
  "total_flos": 1.36616749632e+16,
  "trial_name": null,
  "trial_params": null
}
